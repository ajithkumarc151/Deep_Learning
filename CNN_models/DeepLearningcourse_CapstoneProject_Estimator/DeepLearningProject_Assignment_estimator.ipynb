{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningProject - Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Mb9YuBUQ53oo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Project: Pet Classifier using CNN\n",
        "\n",
        "Prepration\n",
        "- Extract the ipynb file and the data in the same folder\n",
        "\n",
        "Data Set\n",
        "- A production grade program as 10,000 training images\n",
        "- This is a small program with 20 images of cats and 20 images of dogs. \n",
        "- The evaluation set has 10 images of cats and 10 images of dogs\n",
        "\n",
        "Runs\n",
        "- The student is expected to run the 100-300 training step\n",
        "- A production grade code would have about 20k-50k training steps"
      ]
    },
    {
      "metadata": {
        "id": "_u5b8En-53op",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import modules"
      ]
    },
    {
      "metadata": {
        "id": "iZ76UFvE53oq",
        "colab_type": "code",
        "outputId": "eaed230a-9352-4b60-f489-d93ee1e99d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "print(tf.__version__)\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UTTL81he53ot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set hyper parameters\n",
        "- Run the program with three num_steps : 100,200,300"
      ]
    },
    {
      "metadata": {
        "id": "Ci5-ru7xkgjN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "moFXWEgU53ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "img_size = 32\n",
        "num_channels = 3\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "img_shape = (img_size, img_size)\n",
        "trainpath='gdrive/My Drive/data/train'\n",
        "testpath='gdrive/My Drive/data/test'\n",
        "labels = {'cats': 0, 'dogs': 1}\n",
        "fc_size=32 #size of the output of final FC layer\n",
        "num_steps=300 #Try 100, 200, 300. number of steps that training data should be looped. Usually 20K\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0cL-f3Wd53ow",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Read the image dataset"
      ]
    },
    {
      "metadata": {
        "id": "HKWIrGPZ53ow",
        "colab_type": "code",
        "outputId": "1a626ac8-7771-4f5b-832a-6a7e8ce748f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "def read_images_classes(basepath,imgSize=img_size):\n",
        "    image_stack = []\n",
        "    label_stack = []\n",
        "\n",
        "    for counter, l in enumerate(labels):\n",
        "        path = os.path.join(basepath, l,'*g')\n",
        "        for img in glob.glob(path):\n",
        "            one_hot_vector =np.zeros(len(labels),dtype=np.int16)\n",
        "            one_hot_vector[counter]=1\n",
        "            image = cv2.imread(img)\n",
        "            im_resize = cv2.resize(image,img_shape, interpolation=cv2.INTER_CUBIC)\n",
        "            image_stack.append(im_resize)\n",
        "            label_stack.append(labels[l])            \n",
        "    return np.array(image_stack), np.array(label_stack)\n",
        "\n",
        "X_train, y_train=read_images_classes(trainpath)\n",
        "X_test, y_test=read_images_classes(testpath)\n",
        "\n",
        "#test a sample image\n",
        "print('length of train image set',len(X_train))\n",
        "print('X_data shape:', X_train.shape)\n",
        "print('y_data shape:', y_train.shape)\n",
        "\n",
        "fig1 = plt.figure() \n",
        "ax1 = fig1.add_subplot(2,2,1) \n",
        "img = cv2.resize(X_train[0],(64,64), interpolation=cv2.INTER_CUBIC)\n",
        "ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(y_train[0])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of train image set 40\n",
            "X_data shape: (40, 32, 32, 3)\n",
            "y_data shape: (40,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAAC2CAYAAABNl8ZfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngSY20vb/ATfIaZbJcpbWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DJjKGj8S53o2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assignment: Define the tensorflow model\n",
        "\n",
        "The model should have the following layers\n",
        "- input later\n",
        "- conv layer 1 with 32 filters of kernel  size[5,5],\n",
        "- pooling layer 1 with pool size[2,2] and stride 2\n",
        "- conv layer 2 with 64 filters of kernel  size[5,5],\n",
        "- pooling layer 2 with pool size[2,2] and stride 2\n",
        "- dense layer whose output size is fixed in the hyper parameter: fc_size=32\n",
        "- drop out layer with droput probability 0.4\n",
        "- predict the class by doing a softmax on the output of the dropout layers\n",
        "\n",
        "Training\n",
        "- For training fefine the loss function and minimize it\n",
        "- For evaluation calculate the accuracy\n",
        "\n",
        "Reading Material\n",
        "- For ideas look at tensorflow layers tutorial"
      ]
    },
    {
      "metadata": {
        "id": "-TMY5wX453o3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The cnn_model_fn has to be defined here by the student"
      ]
    },
    {
      "metadata": {
        "id": "wmX0iu5853o3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn(features, labels, mode):\n",
        "\n",
        "    tf.random.set_random_seed(42)  \n",
        "  # Input Layer\n",
        "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
        "  #the given images are 32*32 pixels, and have 3  channel\n",
        "    x = features['x']\n",
        "    \n",
        "    input_layer =  tf.reshape(x,[-1,img_size, img_size, num_channels])\n",
        "\n",
        "  # Convolutional Layer #1\n",
        "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
        "  # Padding is added to preserve width and height.\n",
        "  # Input Tensor Shape: [batch_size, 32, 32, 3]\n",
        "  # Output Tensor Shape: [batch_size, 32, 32, 32]\n",
        "    c1 = tf.layers.conv2d(inputs=input_layer, activation=tf.nn.relu, filters=32,\n",
        "                          kernel_size=[5,5], padding='VALID', strides=1, name=\"layer_conv1\")\n",
        "    \n",
        "   # Pooling Layer #1\n",
        "  # First max pooling layer with a 2x2 filter and stride of 2\n",
        "  # Input Tensor Shape: [batch_size, 32, 32, 32]\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 32]\n",
        "    p1 = tf.layers.max_pooling2d(inputs=c1, pool_size=[2,2], strides=2)\n",
        "    \n",
        "    \n",
        "  # Convolutional Layer #2\n",
        "  # Computes 64 features using a 5x5 filter.\n",
        "  # Padding is added to preserve width and height.\n",
        "  # Input Tensor Shape: [batch_size, 16, 16, 32]\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 64]\n",
        "    c2 = tf.layers.conv2d(inputs=p1, activation=tf.nn.relu, filters=64,\n",
        "                          kernel_size=[5,5], padding='VALID', strides=1, name=\"layer_conv2\")\n",
        "    \n",
        "  # Pooling Layer #2\n",
        "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
        "  # Input Tensor Shape: [batch_size, 16, 16, 64]\n",
        "  # Output Tensor Shape: [batch_size, 5, 5, 64]\n",
        "    p2 = tf.layers.max_pooling2d(inputs=c2, pool_size=[2,2], strides=2)\n",
        "\n",
        "  # Flatten tensor into a batch of vectors\n",
        "  # Input Tensor Shape: [batch_size, 5, 5, 64]\n",
        "  # Output Tensor Shape: [batch_size, 5 * 5 * 64]\n",
        "    p2_flat = tf.reshape(p2, [-1, 5 * 5 * 64])\n",
        "    #p2_flat = tf.contrib.layers.flatten(p2)\n",
        "\n",
        "  # Dense Layer\n",
        "  # Densely connected layer with 1024 neurons\n",
        "  # Input Tensor Shape: [batch_size, 5 * 5 * 64]\n",
        "  # Output Tensor Shape: [batch_size, 1024]\n",
        "    fc1 = tf.layers.dense(\n",
        "        inputs=p2_flat, units=1024, activation=tf.nn.relu, name = \"layer_fc1\")\n",
        "    \n",
        "    # Add dropout operation; 0.4 probability that element will be kept\n",
        "    dropout = tf.layers.dropout(\n",
        "      inputs=fc1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    # Logits layer\n",
        "    # Input Tensor Shape: [batch_size, 1024]\n",
        "    # Output Tensor Shape: [batch_size, 32]\n",
        "    logits = tf.layers.dense(inputs = fc1, units=32, name = \"layer_fc2\")\n",
        "    \n",
        "    predictions = {\n",
        "      # Generate predictions (for PREDICT and EVAL mode)\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
        "      # `logging_hook`.\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "  }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "\n",
        "  # Configure the Training Op (for TRAIN mode)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "        train_op = optimizer.minimize(\n",
        "          loss=loss,\n",
        "          global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  # Add evaluation metrics (for EVAL mode)\n",
        "    eval_metric_ops = {\n",
        "        \"accuracy\": tf.metrics.accuracy(\n",
        "            labels=labels, predictions=predictions[\"classes\"])\n",
        "    }\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)     \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2uTVWdj53o5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the tensorflow model\n",
        "\n",
        "This section will use the model defined by the student and run the training and evaluation step"
      ]
    },
    {
      "metadata": {
        "id": "VbybPuOx53o6",
        "colab_type": "code",
        "outputId": "00846303-7901-4d87-f92a-90a6754293c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1410
        }
      },
      "cell_type": "code",
      "source": [
        "#X_train = np.array((X_train/255.0),dtype=np.float16)\n",
        "#X_test = np.array((X_test/255.0), dtype=np.float16)\n",
        "\n",
        "X_train = np.array((X_train/255.0),dtype=np.float32)\n",
        "X_test = np.array((X_test/255.0), dtype=np.float32)\n",
        "\n",
        "# X_train = np.array((X_train/255.0),dtype=np.float64)\n",
        "# X_test = np.array((X_test/255.0), dtype=np.float64)\n",
        "\n",
        "pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"gdrive/My Drive/data/train/tmp/pets_convnet_model\")\n",
        "#pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n",
        "# Set up logging for predictions\n",
        "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
        "\n",
        "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
        "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_train}, y=y_train, batch_size=100,\n",
        "                                                      num_epochs=None, shuffle=True)\n",
        "#num_steps=[100,200,300]\n",
        "\n",
        "pets_classifier.train(input_fn=train_input_fn, steps=300, hooks=[logging_hook])\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_test}, y=y_test, num_epochs=1,shuffle=False)\n",
        "eval_results = pets_classifier.evaluate(input_fn=eval_input_fn)\n",
        "print(eval_results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gdrive/My Drive/data/train/tmp/pets_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fee1d7fc940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gdrive/My Drive/data/train/tmp/pets_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:probabilities = [[0.03760299 0.02543021 0.03279328 ... 0.03405275 0.03068955 0.02578942]\n",
            " [0.03250572 0.02807244 0.03169501 ... 0.03273096 0.02912747 0.02703733]\n",
            " [0.03445126 0.02754067 0.03405284 ... 0.03008236 0.0291354  0.02849994]\n",
            " ...\n",
            " [0.03271832 0.02922692 0.03079751 ... 0.02776637 0.02998809 0.02670183]\n",
            " [0.03668413 0.0275433  0.0321317  ... 0.03096887 0.0310912  0.02718913]\n",
            " [0.03301607 0.0271937  0.0316227  ... 0.03106871 0.02896233 0.02766614]]\n",
            "INFO:tensorflow:loss = 3.4987938, step = 1\n",
            "INFO:tensorflow:probabilities = [[0.52307045 0.47689694 0.00000271 ... 0.00000086 0.00000115 0.00000036]\n",
            " [0.3703624  0.62963766 0.00000001 ... 0.         0.         0.        ]\n",
            " [0.24226277 0.7577354  0.00000019 ... 0.00000005 0.00000006 0.00000002]\n",
            " ...\n",
            " [0.3703624  0.62963766 0.00000001 ... 0.         0.         0.        ]\n",
            " [0.63052887 0.36946708 0.00000036 ... 0.0000001  0.00000016 0.00000004]\n",
            " [0.26649955 0.73346776 0.0000025  ... 0.00000098 0.0000013  0.00000039]] (11.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.39987\n",
            "INFO:tensorflow:probabilities = [[0.4380463  0.5619366  0.00000123 ... 0.00000053 0.00000062 0.00000019]\n",
            " [0.5749345  0.4250628  0.0000002  ... 0.00000007 0.0000001  0.00000002]\n",
            " [0.13322055 0.866774   0.00000047 ... 0.00000013 0.00000018 0.00000004]\n",
            " ...\n",
            " [0.51733917 0.48265344 0.0000006  ... 0.00000018 0.00000037 0.00000007]\n",
            " [0.630445   0.36955503 0.         ... 0.         0.         0.        ]\n",
            " [0.2839562  0.7160388  0.0000004  ... 0.00000011 0.0000002  0.00000004]] (11.362 sec)\n",
            "INFO:tensorflow:loss = 0.35772926, step = 101 (22.731 sec)\n",
            "INFO:tensorflow:probabilities = [[0.8157243  0.18426801 0.0000006  ... 0.00000022 0.00000031 0.00000008]\n",
            " [0.9674521  0.03254789 0.         ... 0.         0.         0.        ]\n",
            " [0.05827064 0.94172937 0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.25746408 0.7425357  0.00000002 ... 0.         0.00000001 0.        ]\n",
            " [0.9030983  0.09690174 0.         ... 0.         0.         0.        ]\n",
            " [0.08332723 0.91667247 0.00000003 ... 0.00000001 0.00000001 0.        ]] (11.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.39168\n",
            "INFO:tensorflow:probabilities = [[0.07409596 0.92590404 0.         ... 0.         0.         0.        ]\n",
            " [0.01446493 0.985535   0.         ... 0.         0.         0.        ]\n",
            " [0.9379552  0.06204482 0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.10294936 0.89705056 0.         ... 0.         0.         0.        ]\n",
            " [0.91397583 0.08602339 0.00000007 ... 0.00000002 0.00000004 0.00000001]\n",
            " [0.9898956  0.01010443 0.         ... 0.         0.         0.        ]] (11.323 sec)\n",
            "INFO:tensorflow:loss = 0.053695664, step = 201 (22.768 sec)\n",
            "INFO:tensorflow:probabilities = [[0.97161746 0.02838249 0.         ... 0.         0.         0.        ]\n",
            " [0.02444102 0.97555894 0.00000001 ... 0.         0.         0.        ]\n",
            " [0.01915587 0.9808442  0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.00872083 0.9912792  0.         ... 0.         0.         0.        ]\n",
            " [0.9859583  0.01404175 0.         ... 0.         0.         0.        ]\n",
            " [0.01042001 0.98958    0.         ... 0.         0.         0.        ]] (11.272 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 300 into gdrive/My Drive/data/train/tmp/pets_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.011291845.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-31T11:01:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/data/train/tmp/pets_convnet_model/model.ckpt-300\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-31-11:01:56\n",
            "INFO:tensorflow:Saving dict for global step 300: accuracy = 0.7, global_step = 300, loss = 0.96549714\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: gdrive/My Drive/data/train/tmp/pets_convnet_model/model.ckpt-300\n",
            "{'accuracy': 0.7, 'loss': 0.96549714, 'global_step': 300}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k8DIcWL353o8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}